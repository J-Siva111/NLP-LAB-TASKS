{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPNvrpTdoCvz9YeIWwb9/um"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1WkxgJRbWgkD","executionInfo":{"status":"ok","timestamp":1760288799872,"user_tz":-330,"elapsed":1159,"user":{"displayName":"JANNU SIVA KRISHNA,CSE(2022) Vel Tech, Chennai","userId":"11343193206217036849"}},"outputId":"50119289-4b71-47ca-c054-939f90eb76ee"},"outputs":[{"output_type":"stream","name":"stdout","text":["Nouns: ['Web', 'este', 'web', 'pagina', 'media', 'example', 'gato', 'dormiendo', 'bano', 'verb', 'prepositions']\n","Verbs: ['ver', 'contains']\n","Adjectives: []\n","Entities: [('muy intersente', 'PERSON')]\n"]}],"source":["import spacy\n","from bs4 import BeautifulSoup  # âœ… Add this line\n","\n","# Load spaCy model (make sure it's installed)\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Function to extract POS and Named Entities\n","def pos_tag_and_extract_info(text):\n","    doc = nlp(text)\n","    nouns = []\n","    verbs = []\n","    adjectives = []\n","    entities = []\n","\n","    for token in doc:\n","        if token.pos_ == \"NOUN\":\n","            nouns.append(token.text)\n","        elif token.pos_ == \"VERB\":\n","            verbs.append(token.text)\n","        elif token.pos_ == \"ADJ\":\n","            adjectives.append(token.text)\n","\n","    for entity in doc.ents:\n","        entities.append((entity.text, entity.label_))\n","\n","    return nouns, verbs, adjectives, entities\n","\n","# Example HTML document\n","web_document = \"\"\"\n","<html>\n","<head>\n","<title>Example Web Page</title>\n","</head>\n","<body>\n","<p>Hola este web pagina es muy intersente y muchas media to ver en la pagina..</p>\n","<p>For example, \"La gato es dormiendo en la bano\" contains a noun, a verb, and prepositions.</p>\n","</body>\n","</html>\n","\"\"\"\n","\n","# Function to extract plain text from HTML\n","def extract_text_from_html(html):\n","    soup = BeautifulSoup(html, 'html.parser')\n","    return soup.get_text()\n","\n","# Run the processing\n","text_content = extract_text_from_html(web_document)\n","nouns, verbs, adjectives, entities = pos_tag_and_extract_info(text_content)\n","\n","# Print results\n","print(\"Nouns:\", nouns)\n","print(\"Verbs:\", verbs)\n","print(\"Adjectives:\", adjectives)\n","print(\"Entities:\", entities)\n"]}]}